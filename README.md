# Multi-Agent Hiring System

This project is a multi-agent system designed to streamline the hiring process by leveraging AI and automation. It uses the **Ollama-hosted Gemma3 model** for natural language processing tasks. The system automates job description summarization, CV extraction, candidate selection, and email notifications for shortlisted candidates.

---

## Table of Contents
1. [Overview](#overview)
2. [Agents in the System](#agents-in-the-system)
4. [Usage Instructions](#usage-instructions)
5. [Example Execution](#example-execution)
6. [Database Management](#database-management)
7. [Text Files](#text-files)
8. [Dependencies](#dependencies)
9. [Contributing](#contributing)
10. [License](#license)

---

## Overview
The Multi-Agent Hiring System automates the recruitment workflow by breaking it into modular tasks handled by specialized agents. Each agent performs a specific task, ensuring scalability, modularity, and maintainability. The system integrates with an SQLite database for persistent storage and supports both real and simulated email notifications.

---

## Agents in the System
1. **JobDescriptionSummarizerAgent**:
   - Summarizes the provided job description into key elements (e.g., skills, experience, qualifications).
   - Writes the summary to `job_description_summary.txt`.

2. **CandidateExtractorAgent**:
   - Extracts and summarizes key information (e.g., skills, experience) from CVs in PDF format.
   - Writes the summaries to `candidate_data.txt`.

3. **HiringManagerAgent**:
   - Matches candidates' CV summaries with the job description summary.
   - Selects the best candidates based on predefined criteria.
   - Writes the selection response to `hiring_manager_response.txt`.

4. **CandidateDataRetrieverAgent**:
   - Extracts specific details ( name, candidate ID, email) for selected candidates.
   - Prepares data for email notifications.

---


## Usage Instructions

### Prerequisites
- Python 3.8 or higher installed.
- Install Ollama and host the **Gemma3 model** locally.
- Ensure all required libraries are installed (see [Dependencies](#dependencies)).

### Steps to Run the System
1. **Clone the Repository**:
   ```bash
   git clone https://github.com/Mohammed-Saajid/MultiAgentHiringSystem.git
   cd MultiAgentHiringSystem
   ```

2. **Install Dependencies**:
   ```bash
   pip install -r requirements.txt
   ```

3. **Run the Application**:
   Execute the `app.py` script in the `src` folder with the following parameters:
   ```bash
   python src/app.py --job_title "Job Title" --job_description "Job Description" --cv_directory "path/to/cv/folder" --email_test 0
   ```
   - `--job_title`: The title of the job (e.g., "Software Engineer").
   - `--job_description`: The full job description text.
   - `--cv_directory`: Path to the folder containing CVs in PDF format.
   - `--email_test`: Set to `1` to send real emails or `0` to simulate sending email invitations.

---

## Example Execution

### Using `example.bat`
1. Navigate to the `example` folder:
   ```bash
   cd example
   ```
2. Run the batch file:
   ```bash
   example.bat
   ```
   This will execute the system with 3 sample CVs located in the `test` folder.

### Using `example.py`
1. Navigate to the `example` folder:
   ```bash
   cd example
   ```
2. Run the script:
   ```bash
   python example.py
   ```
   This will process the entire dataset of job descriptions and CVs.

---

## Database Management
- The system uses an SQLite database for long-term memory storage.
- To reset the database, run the `reset_db.py` script:
  ```bash
  python src/reset_db.py
  ```

---

## Text Files
The following text files are used to store intermediate outputs:
- **candidate_data.txt**: Contains summaries of CVs processed by the `CandidateExtractorAgent`.
- **hiring_manager_response.txt**: Contains responses from the `HiringManagerAgent` regarding candidate selection.
- **job_description_summary.txt**: Contains the summarized job description generated by the `JobDescriptionSummarizerAgent`.

---

## Dependencies
Install the required libraries using `requirements.txt`:
```bash
pip install -r requirements.txt
```

## Dataset
The dataset utilized in this project is provided by **Hack the Future: A Gen AI Sprint Powered by Data**, a hackathon hosted collaboratively by Accenture and GeeksforGeeks. 

## License
This project is licensed under the **MIT License**. See the [LICENSE](LICENSE) file for details.

---

For any questions or issues, please open an issue in the repository or contact the maintainers.